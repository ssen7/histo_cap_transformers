{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Patches: 196\n",
      "Loading Pretrained Local VIT model...\n",
      "Done!\n",
      "Freezing Pretrained Local VIT model\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertLMHeadModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.self.value.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from dataloader import *\n",
    "from utils import *\n",
    "from model_vit_bert import ViTConfigCustom, ViTModelCustom, CustomVEDConfig, CustomVisionEncoderDecoder\n",
    "from training_script_vit_bert import LightningModel\n",
    "\n",
    "# models: Encoder    \n",
    "encoder = ViTModelCustom(config=ViTConfigCustom(hidden_size=576), pretrain_4k='vit4k_xs_dino', freeze_4k=True)\n",
    "\n",
    "# decoder\n",
    "decoder_model_name=\"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "decoder = AutoModelForCausalLM.from_pretrained(decoder_model_name, is_decoder=True, add_cross_attention=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(decoder_model_name)\n",
    "\n",
    "# encoder decoder model\n",
    "model=CustomVisionEncoderDecoder(config=CustomVEDConfig(),encoder=encoder, decoder=decoder)\n",
    "model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "lightning_model = LightningModel(model, tokenizer, model_lr=1e-2)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ckpt=\"/scratch/ss4yd/logs_only_vit_bert/my_model/version_10/checkpoints/epoch=9-val_loss=0.89-step=5000.00.ckpt\"\n",
    "lightning_model.load_state_dict(torch.load(ckpt,map_location=device)['state_dict'])\n",
    "lightning_model.eval()\n",
    "\n",
    "len(list(*decoder.bert.encoder.children())[:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_path='../new_lstm_decoder/data_files/prepared_prelim_data_tokenized_cls256_pathcap_thumb_newsent.pickle'\n",
    "df=pd.read_pickle(df_path)\n",
    "\n",
    "df=df[df.dtype=='test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: GTEX-15TU5-1426\n",
      "Actual Note: \n",
      " this is a heart - left ventricle tissue from a male patient and it has 2 pieces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ss4yd/.local/lib/python3.9/site-packages/transformers/generation/utils.py:1255: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Note: \n",
      " this is a heart - left ventricle tissue from a male patient and it has 2 pieces, no significant ischemic changes \n"
     ]
    }
   ],
   "source": [
    "samp = df.sample(1)\n",
    "\n",
    "pid=samp.pid.values[0]\n",
    "print(f'Patient ID: {pid}')\n",
    "print(f'Actual Note: \\n {samp.new_notes.values[0].lower()}')\n",
    "pixel_values=torch.load(samp.reps_path.values[0]).unsqueeze(0)\n",
    "\n",
    "# generate\n",
    "gencap=lightning_model.model.generate(pixel_values, max_length=128, num_beams=2, do_sample=True)\n",
    "\n",
    "decoded_cap=tokenizer.decode(gencap[0])\n",
    "remove_sptokens=decoded_cap[6:decoded_cap.find('[SEP]')]\n",
    "\n",
    "print(f'Generated Note: \\n {remove_sptokens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: GTEX-14BIN-1426\n",
      "Actual Note: \n",
      " this is a ovary tissue from a female patient and it has 2 pieces; atrophic with corpora albicans\n",
      "Generated Note: \n",
      " this is a ovary tissue from a female patient and it has 2 pieces, typical post menopausal atrophy \n"
     ]
    }
   ],
   "source": [
    "samp = df.sample(1)\n",
    "\n",
    "pid=samp.pid.values[0]\n",
    "print(f'Patient ID: {pid}')\n",
    "print(f'Actual Note: \\n {samp.new_notes.values[0].lower()}')\n",
    "pixel_values=torch.load(samp.reps_path.values[0]).unsqueeze(0)\n",
    "\n",
    "# generate\n",
    "gencap=lightning_model.model.generate(pixel_values, max_length=128, num_beams=2, do_sample=True)\n",
    "\n",
    "decoded_cap=tokenizer.decode(gencap[0])\n",
    "remove_sptokens=decoded_cap[6:decoded_cap.find('[SEP]')]\n",
    "\n",
    "print(f'Generated Note: \\n {remove_sptokens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: GTEX-1AX9K-0326\n",
      "Actual Note: \n",
      " this is a artery - coronary tissue from a male patient and it has 2 pieces; large [50%] intimal plaque in 1 piece, none in other; 60% is external fat\n",
      "Generated Note: \n",
      " this is a adipose - visceral ( omentum ) tissue from a male patient and it has 6 pieces, up to 10x6mm ; \n"
     ]
    }
   ],
   "source": [
    "samp = df.sample(1)\n",
    "\n",
    "pid=samp.pid.values[0]\n",
    "print(f'Patient ID: {pid}')\n",
    "print(f'Actual Note: \\n {samp.new_notes.values[0].lower()}')\n",
    "pixel_values=torch.load(samp.reps_path.values[0]).unsqueeze(0)\n",
    "\n",
    "# generate\n",
    "gencap=lightning_model.model.generate(pixel_values, max_length=128, num_beams=2, do_sample=True)\n",
    "\n",
    "decoded_cap=tokenizer.decode(gencap[0])\n",
    "remove_sptokens=decoded_cap[6:decoded_cap.find('[SEP]')]\n",
    "\n",
    "print(f'Generated Note: \\n {remove_sptokens}')\n",
    "# print(f'Full Generated Note: \\n {decoded_cap}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: GTEX-15CHS-0426\n",
      "Actual Note: \n",
      " this is a artery - tibial tissue from a male patient and it has 2 pieces, no adherent fat/ atherosis\n",
      "Generated Note: \n",
      " this is a artery - tibial tissue from a male patient and it has 2 pieces, no adherent fat \n"
     ]
    }
   ],
   "source": [
    "samp = df.sample(1)\n",
    "\n",
    "pid=samp.pid.values[0]\n",
    "print(f'Patient ID: {pid}')\n",
    "print(f'Actual Note: \\n {samp.new_notes.values[0].lower()}')\n",
    "pixel_values=torch.load(samp.reps_path.values[0]).unsqueeze(0)\n",
    "\n",
    "# generate\n",
    "gencap=lightning_model.model.generate(pixel_values, max_length=128, num_beams=2, do_sample=True)\n",
    "\n",
    "decoded_cap=tokenizer.decode(gencap[0])\n",
    "remove_sptokens=decoded_cap[6:decoded_cap.find('[SEP]')]\n",
    "\n",
    "print(f'Generated Note: \\n {remove_sptokens}')\n",
    "# print(f'Full Generated Note: \\n {decoded_cap}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: GTEX-16BQI-1026\n",
      "Actual Note: \n",
      " this is a breast - mammary tissue tissue from a female patient and it has 2 pieces; 90% fat with scattered atrophic ducts, no lobules\n",
      "Generated Note: \n",
      " this is a adipose - subcutaneous tissue from a male patient and it has 2 pieces ; 10 % fibrovascular content \n"
     ]
    }
   ],
   "source": [
    "samp = df.sample(1)\n",
    "\n",
    "pid=samp.pid.values[0]\n",
    "print(f'Patient ID: {pid}')\n",
    "print(f'Actual Note: \\n {samp.new_notes.values[0].lower()}')\n",
    "pixel_values=torch.load(samp.reps_path.values[0]).unsqueeze(0)\n",
    "\n",
    "# generate\n",
    "gencap=lightning_model.model.generate(pixel_values, max_length=128, num_beams=2, do_sample=True)\n",
    "\n",
    "decoded_cap=tokenizer.decode(gencap[0])\n",
    "remove_sptokens=decoded_cap[6:decoded_cap.find('[SEP]')]\n",
    "\n",
    "print(f'Generated Note: \\n {remove_sptokens}')\n",
    "# print(f'Full Generated Note: \\n {decoded_cap}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: GTEX-13111-0226\n",
      "Actual Note: \n",
      " this is a thyroid tissue from a male patient and it has 2 pieces; multifocal mild stromal fibrosis compromising thyroid follicles\n",
      "Generated Note: \n",
      " this is a thyroid tissue from a male patient and it has 2 pieces, no abnormalities \n"
     ]
    }
   ],
   "source": [
    "samp = df.sample(1)\n",
    "\n",
    "pid=samp.pid.values[0]\n",
    "print(f'Patient ID: {pid}')\n",
    "print(f'Actual Note: \\n {samp.new_notes.values[0].lower()}')\n",
    "pixel_values=torch.load(samp.reps_path.values[0]).unsqueeze(0)\n",
    "\n",
    "# generate\n",
    "gencap=lightning_model.model.generate(pixel_values, max_length=128, num_beams=2, do_sample=True)\n",
    "\n",
    "decoded_cap=tokenizer.decode(gencap[0])\n",
    "remove_sptokens=decoded_cap[6:decoded_cap.find('[SEP]')]\n",
    "\n",
    "print(f'Generated Note: \\n {remove_sptokens}')\n",
    "# print(f'Full Generated Note: \\n {decoded_cap}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: GTEX-ZTX8-1126\n",
      "Actual Note: \n",
      " this is a testis tissue from a male patient and it has 2 pieces\n",
      "Generated Note: \n",
      " this is a testis tissue from a male patient and it has 2 pieces ; spermatogenesis is present \n"
     ]
    }
   ],
   "source": [
    "samp = df.sample(1)\n",
    "\n",
    "pid=samp.pid.values[0]\n",
    "print(f'Patient ID: {pid}')\n",
    "print(f'Actual Note: \\n {samp.new_notes.values[0].lower()}')\n",
    "pixel_values=torch.load(samp.reps_path.values[0]).unsqueeze(0)\n",
    "\n",
    "# generate\n",
    "gencap=lightning_model.model.generate(pixel_values, max_length=128, num_beams=2, do_sample=True)\n",
    "\n",
    "decoded_cap=tokenizer.decode(gencap[0])\n",
    "remove_sptokens=decoded_cap[6:decoded_cap.find('[SEP]')]\n",
    "\n",
    "print(f'Generated Note: \\n {remove_sptokens}')\n",
    "# print(f'Full Generated Note: \\n {decoded_cap}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of BEAM Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEAM Size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: GTEX-13PVR-2726\n",
      "Actual Note: \n",
      " this is a artery - tibial tissue from a female patient and it has 2 pieces, clean specimen, no atherosis\n",
      "Generated Note: \n",
      " this is a artery - tibial tissue from a male patient and it has 2 pieces ; 1 with 40 % and 40 % external fat ; other fibrofatty plaque \n"
     ]
    }
   ],
   "source": [
    "samp = df[df.pid=='GTEX-13PVR-2726']\n",
    "\n",
    "pid=samp.pid.values[0]\n",
    "print(f'Patient ID: {pid}')\n",
    "print(f'Actual Note: \\n {samp.new_notes.values[0].lower()}')\n",
    "pixel_values=torch.load(samp.reps_path.values[0]).unsqueeze(0)\n",
    "\n",
    "# generate\n",
    "gencap=lightning_model.model.generate(pixel_values, max_length=128, num_beams=1, do_sample=True)\n",
    "\n",
    "decoded_cap=tokenizer.decode(gencap[0])\n",
    "remove_sptokens=decoded_cap[6:decoded_cap.find('[SEP]')]\n",
    "\n",
    "print(f'Generated Note: \\n {remove_sptokens}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEAM Size=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: GTEX-13PVR-2726\n",
      "Actual Note: \n",
      " this is a artery - tibial tissue from a female patient and it has 2 pieces, clean specimen, no atherosis\n",
      "Generated Note: \n",
      " this is a artery - tibial tissue from a male patient and it has 2 pieces ; well trimmed \n"
     ]
    }
   ],
   "source": [
    "samp = df[df.pid=='GTEX-13PVR-2726']\n",
    "\n",
    "pid=samp.pid.values[0]\n",
    "print(f'Patient ID: {pid}')\n",
    "print(f'Actual Note: \\n {samp.new_notes.values[0].lower()}')\n",
    "pixel_values=torch.load(samp.reps_path.values[0]).unsqueeze(0)\n",
    "\n",
    "# generate\n",
    "gencap=lightning_model.model.generate(pixel_values, max_length=128, num_beams=2, do_sample=True)\n",
    "\n",
    "decoded_cap=tokenizer.decode(gencap[0])\n",
    "remove_sptokens=decoded_cap[6:decoded_cap.find('[SEP]')]\n",
    "\n",
    "print(f'Generated Note: \\n {remove_sptokens}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEAM Size=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: GTEX-13PVR-2726\n",
      "Actual Note: \n",
      " this is a artery - tibial tissue from a female patient and it has 2 pieces, clean specimen, no atherosis\n",
      "Generated Note: \n",
      " this is a artery - tibial tissue from a male patient and it has 2 pieces ; well dissected ; no plaques ; no plaques \n"
     ]
    }
   ],
   "source": [
    "samp = df[df.pid=='GTEX-13PVR-2726']\n",
    "\n",
    "pid=samp.pid.values[0]\n",
    "print(f'Patient ID: {pid}')\n",
    "print(f'Actual Note: \\n {samp.new_notes.values[0].lower()}')\n",
    "pixel_values=torch.load(samp.reps_path.values[0]).unsqueeze(0)\n",
    "\n",
    "# generate\n",
    "gencap=lightning_model.model.generate(pixel_values, max_length=128, num_beams=3, do_sample=True)\n",
    "\n",
    "decoded_cap=tokenizer.decode(gencap[0])\n",
    "remove_sptokens=decoded_cap[6:decoded_cap.find('[SEP]')]\n",
    "\n",
    "print(f'Generated Note: \\n {remove_sptokens}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEAM Size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: GTEX-13PVR-2726\n",
      "Actual Note: \n",
      " this is a artery - tibial tissue from a female patient and it has 2 pieces, clean specimen, no atherosis\n",
      "Generated Note: \n",
      " this is a artery - tibial tissue from a male patient and it has 2 pieces, no adherent fat, delineated \n"
     ]
    }
   ],
   "source": [
    "samp = df[df.pid=='GTEX-13PVR-2726']\n",
    "\n",
    "pid=samp.pid.values[0]\n",
    "print(f'Patient ID: {pid}')\n",
    "print(f'Actual Note: \\n {samp.new_notes.values[0].lower()}')\n",
    "pixel_values=torch.load(samp.reps_path.values[0]).unsqueeze(0)\n",
    "\n",
    "# generate\n",
    "gencap=lightning_model.model.generate(pixel_values, max_length=128, num_beams=4, do_sample=True)\n",
    "\n",
    "decoded_cap=tokenizer.decode(gencap[0])\n",
    "remove_sptokens=decoded_cap[6:decoded_cap.find('[SEP]')]\n",
    "\n",
    "print(f'Generated Note: \\n {remove_sptokens}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEAM Size=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: GTEX-13PVR-2726\n",
      "Actual Note: \n",
      " this is a artery - tibial tissue from a female patient and it has 2 pieces, clean specimen, no atherosis\n",
      "Generated Note: \n",
      " this is a artery - tibial tissue from a male patient and it has 2 pieces, no adherent fat, delineated \n"
     ]
    }
   ],
   "source": [
    "samp = df[df.pid=='GTEX-13PVR-2726']\n",
    "\n",
    "pid=samp.pid.values[0]\n",
    "print(f'Patient ID: {pid}')\n",
    "print(f'Actual Note: \\n {samp.new_notes.values[0].lower()}')\n",
    "pixel_values=torch.load(samp.reps_path.values[0]).unsqueeze(0)\n",
    "\n",
    "# generate\n",
    "gencap=lightning_model.model.generate(pixel_values, max_length=128, num_beams=5, do_sample=True)\n",
    "\n",
    "decoded_cap=tokenizer.decode(gencap[0])\n",
    "remove_sptokens=decoded_cap[6:decoded_cap.find('[SEP]')]\n",
    "\n",
    "print(f'Generated Note: \\n {remove_sptokens}')\n",
    "# print(f'Full Generated Note: \\n {decoded_cap}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.12.0",
   "language": "python",
   "name": "pytorch-1.12.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
